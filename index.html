<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Numair Khan</title>
  
  <meta name="author" content="Numair Khan">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Numair Khan</name>
              </p>
              <p>I am a research scientist at <a href="https://about.meta.com/realitylabs/">Meta Reality Labs</a> in Redmond, Washington. I work on computer vision and machine learning for applications in computational photography.
              </p>
	      <p>I completed my PhD at <a href="https://visual.cs.brown.edu/">Brown</a> where I was advised by <a href="https://jamestompkin.com/">James Tompkin</a>. I received a Fulbright Scholarship for my Masters at the <a href="https://cims.nyu.edu/">Courant Institute</a> of New York University where my Master's thesis was advised by <a href="https://cs.nyu.edu/~perlin/">Ken Perlin</a>.  
              </p>
              <p style="text-align:center">
                <a href="mailto:numair_khan@brown.edu">Email</a> &nbsp/&nbsp
                <a href="data/NumairKhan-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=B_mk94MAAAAJ&hl=en&oi=sra">Google Scholar</a> 
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="img/NumairKhan.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="img/NumairKhan_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				

<tr onmouseout="gauffre_stop()" onmouseover="gauffre_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='gauffre_image'><video  width=100% height=100% muted autoplay loop>
      <source src="img/gauffre.mp4" type="video/mp4">
      Your browser does not support the video tag.
      </video></div>
      <img src='img/thumb-gauffre.gif' width="160">
    </div>
    <script type="text/javascript">
      function gauffre_start() {
        document.getElementById('gauffre_image').style.opacity = "1";
      }

      function gauffre_stop() {
        document.getElementById('gauffre_image').style.opacity = "0";
      }
      gauffre_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <papertitle>GauFRe: Gaussian Deformation Fields for Real-time Dynamic Novel View Synthesis</papertitle>
    <br>
    <a href="https://lynl7130.github.io/">Yiqing Liang</a>,
    <strong>Numair Khan</strong>,
    <a href="">Zhenqin Li</a>,
    <a href="https://www.monkeyoverflow.com/about">Thu Nguyen-Phuoc</a>,
    Douglas Lanman,    
    <a href="https://jamestompkin.com/">James Tompkin</a>,
    <a href="https://leixiao-ubc.github.io/">Lei Xiao</a>,
    <br>
    <em>ArXiv</em>, 2024 &nbsp 
    <br>
    <a href="https://arxiv.org/abs/2312.11458">arXiv</a> /
    <a href="https://lynl7130.github.io/gaufre/index.html">project page</a> /
    <a href="./data/liang2024gauffre.bib">bibtex</a>
    <p></p>
    <p>
      We propose a method for dynamic scene reconstruction based on a deformable set of 3D Gaussians residing in a canonical space, and a time-dependent deformation field defined by a multi-layer perceptron (MLP)
    </p>
  </td>
</tr>
	    

<tr onmouseout="texturedreamer_stop()" onmouseover="texturedreamer_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='texturedreamer_image'><video  width=100% height=100% muted autoplay loop>
      <source src="img/texture-dreamer.mp4" type="video/mp4">
      Your browser does not support the video tag.
      </video></div>
      <img src='img/thumb-texture-dreamer.gif' width="160">
    </div>
    <script type="text/javascript">
      function texturedreamer_start() {
        document.getElementById('texturedreamer_image').style.opacity = "1";
      }

      function texturedreamer_stop() {
        document.getElementById('texturedreamer_image').style.opacity = "0";
      }
      texturedreamer_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <papertitle>TextureDreamer: Image-guided Texture Synthesis through Geometry-aware Diffusion</papertitle>
    <br>
    <a href="https://yuyingyeh.github.io/">Yu-Ying Yeh</a>,
    <a href="https://jbhuang0604.github.io/">Jia-Bin Huang</a>,
    <a href="https://changilkim.com/">Changil Kim</a>,
    <a href="https://leixiao-ubc.github.io/">Lei Xiao</a>,
    <a href="https://www.monkeyoverflow.com/about">Thu Nguyen-Phuoc</a>,
    <strong>Numair Khan</strong>,
    <a href="https://holmes969.github.io/">Cheng Zhang</a>,
    <a href="https://cseweb.ucsd.edu/~mkchandraker/">Manmohan Chandrakar</a>,
    <a href="">Carl Marshall</a>,
    <a href="http://flycooler.com/">Zhao Dong</a>,
    <a href="">Zhenqin Li</a>,
    <br>
    <em>ArXiv</em>, 2024 &nbsp 
    <br>
    <a href="https://arxiv.org/abs/2401.09416">arXiv</a> /
    <a href="https://texturedreamer.github.io/">project page</a> /
    <a href="./data/yeh2024texturedreamer.bib">bibtex</a>
    <p></p>
    <p>
      We present a novel image-guided texture synthesis method to transfer relightable textures from a small number of input images to target 3D shapes across arbitrary categories.
    </p>
  </td>
</tr>


<tr onmouseout="tmpi_stop()" onmouseover="tmpi_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='tmpi_image'><video  width=100% height=100% muted autoplay loop>
      <source src="img/tmpi.mp4" type="video/mp4">
      Your browser does not support the video tag.
      </video></div>
      <img src='img/thumb-tmpi.gif' width="160">
    </div>
    <script type="text/javascript">
      function tmpi_start() {
        document.getElementById('tmpi_image').style.opacity = "1";
      }

      function tmpi_stop() {
        document.getElementById('tmpi_image').style.opacity = "0";
      }
      tmpi_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <papertitle>Tiled Multiplane Images for Practical 3D Photography</papertitle>
    <br>
    <strong>Numair Khan</strong>,
    Douglas Lanman,
    <a href="https://leixiao-ubc.github.io">Lei Xiao</a>,
    <br>
    <em>ICCV</em>, 2023 &nbsp 
    <br>
    <a href="https://arxiv.org/abs/2309.14291">arXiv</a> /
    <a href="">code [coming soon]</a> /
    <a href="./data/khan2023tmpi.bib">bibtex</a>
    <p></p>
    <p>
      We propose a method for generating tiled multiplane images with only a small number of adaptive depth planes
      for single-view 3D photography in the wild.
    </p>
  </td>
</tr>


<tr onmouseout="tcod_stop()" onmouseover="tcod_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='tcod_image'><video  width=100% height=100% muted autoplay loop>
      <source src="img/tcod.mp4" type="video/mp4">
      Your browser does not support the video tag.
      </video></div>
      <img src='img/thumb-tcod.gif' width="160">
    </div>
    <script type="text/javascript">
      function tcod_start() {
        document.getElementById('tcod_image').style.opacity = "1";
      }

      function tcod_stop() {
        document.getElementById('tcod_image').style.opacity = "0";
      }
      tcod_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://research.facebook.com/publications/temporally-consistent-online-depth-estimation-using-point-based-fusion/">
      <papertitle>Temporally Consistent Online Depth Estimation Using Point-Based Fusion</papertitle>
    </a>
    <br>
    <strong>Numair Khan</strong>, Eric Penner, Douglas Lanman,
    <a href="https://leixiao-ubc.github.io">Lei Xiao</a>,
    <br>
    <em>CVPR</em>, 2023 &nbsp 
    <br>
    <a href="https://arxiv.org/abs/2304.07435">arXiv</a> /
    <a href="https://github.com/facebookresearch/TemporallyConsistentDepth">code</a> /
    <a href="./data/khan2023tcod.bib">bibtex</a>
    <p></p>

    <p></p>
    <p>
      We aim to estimate temporally consistent depth maps of video streams in an online setting by using a global point cloud along with a learned fusion approach in image space.
    </p>
  </td>
</tr>

          
<tr onmouseout="neuralfields_stop()" onmouseover="neuralfields_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='neuralfields_image'>
        <img src='img/thumb-neuralfields.gif' width="160"></div>
      <img src='img/thumb-neuralfields-over.gif' width="160">
    </div>
    <script type="text/javascript">
      function neuralfields_start() {
          document.getElementById('neuralfields_image').style.opacity = "1";
      }
      
      function neuralfields_stop() {
          document.getElementById('neuralfields_image').style.opacity = "0";
      }
      neuralfields_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://neuralfields.cs.brown.edu/eg22.html">
      <papertitle>Neural Fields in Visual Computing and Beyond</papertitle>
    </a>
    <br>
    <a href="https://yxie20.github.io">Yiheng Xie</a>, 
    <a href="https://tovacinni.github.io">Towaki Takikawa</a>, 
    <a href="https://www-scf.usc.edu/~saitos/">Shunsuke Saito</a>, 
    <a href="http://orlitany.github.io/">Or Litany</a>, 
    <a href="https://player-eric.com/about/">Shiqin Yan</a>, 
    <strong>Numair Khan</strong>,
    <a href="https://federicotombari.github.io">Federico Tombari</a>
    <a href="https://jamestompkin.com">James Tompkin</a>
    <a href="https://vincentsitzmann.com">Vincent Sitzmann</a>
    <a href="https://cs.brown.edu/people/ssrinath">Srinath Sridhar</a>
    <br>
    <em>Eurographics State-of-the-Art Report</em>, 2022
    <br>
    <a href="https://neuralfields.cs.brown.edu/eg22.html">project page</a> /
    <a href="https://neuralfields.cs.brown.edu/">website</a> /
    <a href="https://arxiv.org/abs/2111.11426">arXiv</a>
    <p></p>
    <p>
     We present a comprehensive review of neural fields by providing context, mathematical grounding, and an extensive literature review.
     A companion website contributes a living version that can be continually updated by the community.
    </p>
  </td>
</tr>		


<tr onmouseout="diffdiff_stop()" onmouseover="diffdiff_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='diffdiff_image'>
        <img src='img/thumb-diffdiff-over.gif' width="160"></div>
      <img src='img/thumb-diffdiff.gif' width="160">
    </div>
    <script type="text/javascript">
      function diffdiff_start() {
          document.getElementById('diffdiff_image').style.opacity = "1";
      }
      
      function diffdiff_stop() {
          document.getElementById('diffdiff_image').style.opacity = "0";
      }
      diffdiff_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://visual.cs.brown.edu/projects/diffdiffdepth-webpage/">
      <papertitle>Differentiable Diffusion for Dense Depth Estimation from Multi-View Images</papertitle>
    </a>
    <br>
    <strong>Numair Khan</strong>
    <a href="https://vclab.kaist.ac.kr/minhkim/">Min H. Kim</a>, 
    <a href="https://jamestompkin.com">James Tompkin</a>
    <br>
    <em>CVPR</em>, 2021
    <br>
    <a href="https://visual.cs.brown.edu/projects/diffdiffdepth-webpage/">project page</a> /
    <a href="https://github.com/brownvc/diffdiffdepth">code</a> /
    <a href="https://arxiv.org/abs/2106.08917">arXiv</a> /
    <a href="./data/khan2021diffdiffdepth.bib">bibtex</a>
    <p></p>
    <p>
      A method to estimate dense depth by optimizing a sparse set of points such that their diffusion into a depth map minimizes a multi-view reprojection error from RGB supervision.
    </p>
  </td>
</tr>		



<tr onmouseout="bidirectional_stop()" onmouseover="bidirectional_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='bidirectional_image'>
        <img src='img/thumb-bidirectional-after.gif' width="160"></div>
      <img src='img/thumb-bidirectional-before.gif' width="160">
    </div>
    <script type="text/javascript">
      function bidirectional_start() {
          document.getElementById('bidirectional_image').style.opacity = "1";
      }
      
      function bidirectional_stop() {
          document.getElementById('bidirectional_image').style.opacity = "0";
      }
      bidirectional_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://visual.cs.brown.edu/projects/lightfielddepth-webpage/">
      <papertitle>Edge-Aware Bidirectional Diffusion for Dense Depth Estimation from Light Fields</papertitle>
    </a>
    <br>
    <strong>Numair Khan</strong>,
    <a href="https://vclab.kaist.ac.kr/minhkim/">Min H. Kim</a>, 
    <a href="https://jamestompkin.com">James Tompkin</a>
    <br>
    <em>BMVC</em>, 2021
    <br>
    <a href="https://arxiv.org/abs/2107.02967">arXiv</a> /
    <a href="https://visual.cs.brown.edu/projects/lightfielddepth-webpage/">project page</a> /
    <a href="https://github.com/brownvc/lightfielddepth">code</a> /
    <a href="./data/khan2021bidirectional.bib">bibtex</a>
    <p></p>
    <p>
      We present an algorithm to estimate fast and accurate depth maps from light fields via a sparse set of depth edges and gradients.
    </p>
  </td>
</tr>		


<tr onmouseout="vclfd_stop()" onmouseover="vclfd_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='vclfd_image'><video  width=100% height=100% muted autoplay loop>
      <source src="img/vclfd.mp4" type="video/mp4">
      Your browser does not support the video tag.
      </video></div>
      <img src='img/thumb-vclfd.gif' width="160">
    </div>
    <script type="text/javascript">
      function vclfd_start() {
        document.getElementById('vclfd_image').style.opacity = "1";
      }

      function vclfd_stop() {
        document.getElementById('vclfd_image').style.opacity = "0";
      }
      vclfd_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://visual.cs.brown.edu/projects/lightfielddepth-webpage/">
      <papertitle>View-Consistent 4D Light Field Depth Estimation</papertitle>
    </a>
    <br>
    <strong>Numair Khan</strong>,
    <a href="https://vclab.kaist.ac.kr/minhkim/">Min H. Kim</a>, 
    <a href="https://jamestompkin.com">James Tompkin</a>
    <br>
    <em>BMVC</em>, 2020
    <br>
    <a href="https://arxiv.org/abs/2009.04065">arXiv</a> /
    <a href="https://visual.cs.brown.edu/projects/lightfielddepth-webpage/">project page</a> /
    <a href="https://github.com/brownvc/lightfielddepth">code</a> /
    <a href="./data/khan2020vclfd.bib">bibtex</a>
    <p></p>
    <p>
    We propose a method to compute depth maps for every sub-aperture image in a light field in a view-consistent way.
    </p>
  </td>
</tr>


<tr onmouseout="vclfs_stop()" onmouseover="vclfs_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='vclfs_image'><video  width=100% height=100% muted autoplay loop>
      <source src="img/vclfs.mp4" type="video/mp4">
      Your browser does not support the video tag.
      </video></div>
      <img src='img/thumb-vclfs.gif' width="160">
    </div>
    <script type="text/javascript">
      function vclfs_start() {
        document.getElementById('vclfs_image').style.opacity = "1";
      }

      function vclfs_stop() {
        document.getElementById('vclfs_image').style.opacity = "0";
      }
      vclfs_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://github.com/brownvc/lightfieldsuperpixels">
      <papertitle>View-Consistent 4D Light Field Superpixel Segmentation</papertitle>
    </a>
    <br>
    <strong>Numair Khan</strong>,
    <a href="">Qian Zhang</a>,
    Lucas Kasser, Henry Stone,
    <a href="https://vclab.kaist.ac.kr/minhkim/">Min H. Kim</a>, 
    <a href="https://jamestompkin.com">James Tompkin</a>
    <br>
    <em>ICCV</em>, 2019 (Oral Presentation)
    <br>
    <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Khan_View-Consistent_4D_Light_Field_Superpixel_Segmentation_ICCV_2019_paper.pdf">paper</a> /
    <a href="https://github.com/brownvc/lightfieldsuperpixels">code</a> /
    <a href="./data/khan2019vclfs.bib">bibtex</a>
    <p></p>
    <p>
    We use occlusion-aware angular segmentation of an Epipolar Plane Image (EPI) to generate light field superpixels that are consistent across views.
    </p>
  </td>
</tr>


<tr onmouseout="minimap_stop()" onmouseover="minimap_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='minimap_image'>
        <img src='img/thumb-minimap-after.gif' width="160"></div>
      <img src='img/thumb-minimap-before.gif' width="160">
    </div>
    <script type="text/javascript">
      function minimap_start() {
          document.getElementById('minimap_image').style.opacity = "1";
      }
      
      function minimap_stop() {
          document.getElementById('minimap_image').style.opacity = "0";
      }
      minimap_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://www.tandfonline.com/doi/abs/10.1080/10447318.2017.1418804">
      <papertitle>Rethinking the Mini-Map: A Navigational Aid to Support Spatial Learning in Urban Game Environments</papertitle>
    </a>
    <br>
    <strong>Numair Khan</strong>,
    <a href="https://sites.google.com/view/anis-ur-rahman">Anis Ur Rahman</a>
    <br>
    <em>IJHCI</em>, 2017
    <br>
    <a href="./papers/khan2017minimap.pdf">paper</a> /
    <a href="./data/khan2017minimap.bib">bibtex</a>
    <p></p>
    <p>
      We propose landmark-based verbal directions as an alternative to mini-maps, and examine the development of spatial knowledge in an
      open-world urban game environment.
    </p>
  </td>
</tr>		


<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <img src='img/thumb-prediction.gif' width="160">
    </div>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S1574119217301530?via%3Dihub">
      <papertitle>Data Analysis and Call Prediction on Dyadic Data from an Understudied Population</papertitle>
    </a>
    <br>
    Mehwish Nasim, Aimal Rextin, Shumaila Hayat,
    <strong>Numair Khan</strong>, Mudassir Malik
    <br>
    <em>Pervasive and Mobile Computing</em>, 2017
    <br>
    <a href="./papers/nasim2017call.pdf">paper</a> /
    <a href="./data/nasim2017call.bib">bibtex</a>
    <p></p>
    <p>
      Predicting outgoing mobile phone calls using machine learning and time clusters-based approaches.
    </p>
  </td>
</tr>		


<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <img src='img/thumb-distance-transform.gif' width="160">
    </div>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="./papers/khan2017gpu.pdf">
      <papertitle>Space-Efficient Pointwise Computation of the Distance Transform on GPUs</papertitle>
    </a>
    <br>
    <strong>Numair Khan</strong>, <a href="http://www.mzahran.com">Mohamed Zahran</a>
    <br>
    <em>International Parallel and Distributed Processing Symposium Workshops (IPDPSW)</em>, 2017
    <br>
    <a href="./papers/khan2017gpu.pdf">paper</a> /
    <a href="./data/khan2017gpu.bib">bibtex</a>
    <p></p>
    <p>
      The distance transform is decomposed into a map-and-reduction pattern for efficient computation on GPUs.
    </p>
  </td>
</tr>		


<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <img src='img/thumb-calllogs.gif' width="160">
    </div>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://dl.acm.org/doi/10.1145/2935334.2935350">
      <papertitle>Understanding Call Logs of Smartphone Users for Making Future Calls</papertitle>
    </a>
    <br>
    Mehwish Nasim, Aimal Rextin,
    <strong>Numair Khan</strong>, Mudassir Malik
    <br>
    <em>International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI)</em>, 2016
    <br>
    <a href="./papers/nasim2016call.pdf">paper</a> /
    <a href="./data/nasim2016call.bib">bibtex</a>
    <p></p>
    <p>
      In this measurement study, we analyze whether mobile phone users exhibit temporal regularity in their mobile communication.
    </p>
  </td>
</tr>		


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Misc</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="img/thumb-xrds.gif"></td>
            <td width="75%" valign="center">
              <a href="https://dl.acm.org/doi/10.1145/3416051">In Search of a Strategy Against Misinformation</a>
              <br>
              <a href="https://dl.acm.org/doi/10.1145/3100135">I, Entrepreneur</a>
              <br>
              <a href="https://dl.acm.org/doi/10.1145/2684377">The Essentials of a Computer Scientist's Toolkit</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img style="width:95%" src="img/thumb-brown-cs.png" alt="brown-cs">
            </td>
            <td width="75%" valign="center">
              <a href="https://cs.brown.edu/courses/csci1290/">Teaching Assistant, CSCI 1290 - Computational Photography, Fall 2020</a>
              <br>
              <a href="https://cs.brown.edu/courses/csci1290/2018_Fall/index.html">Teaching Assistant, CSCI 1290 - Computational Photography, Fall 2018</a>
	      <br>
	      Teaching Assistant, CSCI 2240 - Interactive Computer Graphics, Spring 2018</a>
            </td>
          </tr>

	  <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img style="width:75%;padding:0px 20px 0px 20px" src="img/thumb-nust.png" alt="nust">
            </td>
            <td width="75%" valign="center">
              Instructor, Advanced Programming Spring 2016
              <br>
	      Instructor, Operating Systems Fall 2015
              <br>
            </td>
          </tr>

					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
		The source code for this website was copied from <a href="https://jonbarron.info/">Jon Barron's</a> website. It is freely available for personal use <a href="https://github.com/jonbarron/jonbarron_website">here</a>.   
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
